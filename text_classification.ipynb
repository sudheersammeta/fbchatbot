{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['About Class', 'Exam Details', 'Greetings', 'Project Details', 'Syllabus', 'Valediction', 'Professor Name', 'Office Hours', 'Office Location', 'Lecture Timings', 'Lecture Location', 'Class Location']\n",
    "dataframe = pd.read_table(\"./JSGF_Files/professorName.txt\", header=None)\n",
    "dataframe['class'] = 6\n",
    "train_data = dataframe\n",
    "#print train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"./JSGF_Files/officeHours.txt\", header=None)\n",
    "dataframe['class'] = 7 #'Office Hours'#1\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"./JSGF_Files/officeLocation.txt\", header=None)\n",
    "dataframe['class'] = 8 #'Office Location'#2\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"./JSGF_Files/lectureTimings.txt\", header=None)\n",
    "dataframe['class'] = 9 #'Lecture Timings'#3\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"./JSGF_Files/lectureLocation.txt\", header=None)\n",
    "dataframe['class'] = 10 #'Lecture Location'#4\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"./JSGF_Files/classLocation.txt\", header=None)\n",
    "dataframe['class'] = 11 #'Class Location'#5\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"./JSGF_Files/aboutClass.txt\", header=None)\n",
    "dataframe['class'] = 0\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"./JSGF_Files/examDetails.txt\", header=None)\n",
    "dataframe['class'] = 1\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"./JSGF_Files/greetings.txt\", header=None)\n",
    "dataframe['class'] = 2\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"./JSGF_Files/projectDetails.txt\", header=None)\n",
    "dataframe['class'] = 3\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"./JSGF_Files/syllabus.txt\", header=None)\n",
    "dataframe['class'] = 4\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"./JSGF_Files/valediction.txt\", header=None)\n",
    "dataframe['class'] = 5\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     0  class\n",
      "0                                       name professor      6\n",
      "1                                        name lecturer      6\n",
      "2                                      name instructor      6\n",
      "3                                         name teacher      6\n",
      "4                                   name the professor      6\n",
      "5                                    name the lecturer      6\n",
      "6                                  name the instructor      6\n",
      "7                                     name the teacher      6\n",
      "8                                    name of professor      6\n",
      "9                                     name of lecturer      6\n",
      "10                                  name of instructor      6\n",
      "11                                     name of teacher      6\n",
      "12                               name of the professor      6\n",
      "13                                name of the lecturer      6\n",
      "14                              name of the instructor      6\n",
      "15                                 name of the teacher      6\n",
      "16                                  the name professor      6\n",
      "17                                   the name lecturer      6\n",
      "18                                 the name instructor      6\n",
      "19                                    the name teacher      6\n",
      "20                              the name the professor      6\n",
      "21                               the name the lecturer      6\n",
      "22                             the name the instructor      6\n",
      "23                                the name the teacher      6\n",
      "24                               the name of professor      6\n",
      "25                                the name of lecturer      6\n",
      "26                              the name of instructor      6\n",
      "27                                 the name of teacher      6\n",
      "28                           the name of the professor      6\n",
      "29                            the name of the lecturer      6\n",
      "..                                                 ...    ...\n",
      "744                     what is the greensheet of shim      4\n",
      "745               what is the greensheet of shim class      4\n",
      "746             what is the greensheet of shim lecture      4\n",
      "747             what is the greensheet of shim CMPE297      4\n",
      "748                 what is the greensheet of shim 297      4\n",
      "749            what is the greensheet of shim CMPE-297      4\n",
      "750            what is the greensheet of shim CMPE 297      4\n",
      "751       what is the greensheet of shim deep learning      4\n",
      "752               what is the greensheet of simon shim      4\n",
      "753         what is the greensheet of simon shim class      4\n",
      "754       what is the greensheet of simon shim lecture      4\n",
      "755       what is the greensheet of simon shim CMPE297      4\n",
      "756           what is the greensheet of simon shim 297      4\n",
      "757      what is the greensheet of simon shim CMPE-297      4\n",
      "758      what is the greensheet of simon shim CMPE 297      4\n",
      "759  what is the greensheet of simon shim deep lear...      4\n",
      "760                  what is the greensheet of mr shim      4\n",
      "761            what is the greensheet of mr shim class      4\n",
      "762          what is the greensheet of mr shim lecture      4\n",
      "763          what is the greensheet of mr shim CMPE297      4\n",
      "764              what is the greensheet of mr shim 297      4\n",
      "765         what is the greensheet of mr shim CMPE-297      4\n",
      "766         what is the greensheet of mr shim CMPE 297      4\n",
      "767    what is the greensheet of mr shim deep learning      4\n",
      "0                                                  bye      5\n",
      "1                                                  cya      5\n",
      "2                                              goodbye      5\n",
      "3                                               See ya      5\n",
      "4                                              bye-bye      5\n",
      "5                                             good bye      5\n",
      "\n",
      "[7524 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print (train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name professor' 'name lecturer' 'name instructor' ..., 'See ya' 'bye-bye'\n",
      " 'good bye']\n",
      "[[6]\n",
      " [6]\n",
      " [6]\n",
      " ..., \n",
      " [5]\n",
      " [5]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(train_data[0])\n",
    "y_train = np.array(train_data['class'])\n",
    "x_test = np.array(train_data[0])\n",
    "y_test = np.array(train_data['class'])\n",
    "print (x_train)\n",
    "y_train = np.array(y_train).reshape([-1, 1])\n",
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(x_train)\n",
    "x_train_dtm = vect.transform(x_train)\n",
    "x_test_dtm = vect.transform(x_test)\n",
    "input_size =  len(vect.get_feature_names())\n",
    "#print x_train_dtm\n",
    "simple_train_dtm = vect.transform(x_train)\n",
    "#simple_train_dtm\n",
    "#pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())\n",
    "x_cnn = np.array(simple_train_dtm.toarray(), np.float32)\n",
    "print (x_cnn[0])\n",
    "#y_cnn = np.array(tf.one_hot(y_train,6))\n",
    "#print y_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(x_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 468,    0,    0,    0,   12,    0,    0,    0,    0,   20,   60,\n",
       "           0],\n",
       "       [   0,  108,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [   0,    4,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,   80,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,  768,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [   0,    2,    0,    0,    0,    4,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,    0,    0,   88,    0,    0,    4,    4,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 2064,    0,    0,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,   15,  295,    0,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0, 1800,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,   15, 1695,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    8,\n",
       "           8]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class = nb.predict(x_test_dtm)\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professor Name\n"
     ]
    }
   ],
   "source": [
    "print (class_labels[np.asscalar(nb.predict(x_test_dtm[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "query = [\"syllabus\"]\n",
    "msg = vect.transform(query)\n",
    "msg =  msg.toarray()\n",
    "print (msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syllabus\n"
     ]
    }
   ],
   "source": [
    "print (class_labels[np.asscalar(nb.predict(msg))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input placeholders\n",
    "X = tf.placeholder(tf.float32, [None, input_size])\n",
    "X_img = tf.reshape(X, [-1,1,input_size,1]) \n",
    "y = tf.placeholder(tf.int32, [None, 1])\n",
    "Y = tf.one_hot(y,6)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X_img, W1,strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 6], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([6]))\n",
    "hypothesis = tf.matmul(L2, W3) + b\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 12;\n",
    "X = tf.placeholder(tf.float32, [None, input_size])\n",
    "y = tf.placeholder(tf.int32, [None, 1])\n",
    "Y = tf.one_hot(y, n_class)\n",
    "W1 = tf.Variable(tf.truncated_normal([input_size, 256], stddev=math.sqrt(2.0/(28*28))))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "W2 = tf.Variable(tf.truncated_normal([256, 64], stddev=math.sqrt(2.0/(256))))\n",
    "b2 = tf.Variable(tf.zeros([64]))\n",
    "W3 = tf.Variable(tf.truncated_normal([64, n_class], stddev=math.sqrt(2.0/(64))))\n",
    "b3 = tf.Variable(tf.zeros([n_class]))\n",
    "layer1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1, W2) + b2)\n",
    "hypothesis = tf.nn.relu(tf.matmul(layer2, W3) + b3)\n",
    "prediction = tf.nn.softmax(hypothesis)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=hypothesis))\n",
    "cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "summary = tf.summary.merge_all()\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.03).minimize(cost)\n",
    "is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning stared. It takes sometime.\n",
      "Epoch: 0001 cost = 2.487577677\n",
      "Epoch: 0002 cost = 2.483402014\n",
      "Epoch: 0003 cost = 2.478536367\n",
      "Epoch: 0004 cost = 2.472835779\n",
      "Epoch: 0005 cost = 2.466172218\n",
      "Epoch: 0006 cost = 2.458576918\n",
      "Epoch: 0007 cost = 2.450049639\n",
      "Epoch: 0008 cost = 2.440713167\n",
      "Epoch: 0009 cost = 2.430703878\n",
      "Epoch: 0010 cost = 2.420106888\n",
      "Epoch: 0011 cost = 2.408993721\n",
      "Epoch: 0012 cost = 2.397382498\n",
      "Epoch: 0013 cost = 2.385179520\n",
      "Epoch: 0014 cost = 2.372308731\n",
      "Epoch: 0015 cost = 2.358728647\n",
      "Epoch: 0016 cost = 2.344195604\n",
      "Epoch: 0017 cost = 2.328671217\n",
      "Epoch: 0018 cost = 2.312026978\n",
      "Epoch: 0019 cost = 2.294135332\n",
      "Epoch: 0020 cost = 2.274943590\n",
      "Epoch: 0021 cost = 2.254321575\n",
      "Epoch: 0022 cost = 2.232161045\n",
      "Epoch: 0023 cost = 2.208377361\n",
      "Epoch: 0024 cost = 2.182839155\n",
      "Epoch: 0025 cost = 2.155484915\n",
      "Epoch: 0026 cost = 2.126267195\n",
      "Epoch: 0027 cost = 2.095257521\n",
      "Epoch: 0028 cost = 2.062632322\n",
      "Epoch: 0029 cost = 2.028730154\n",
      "Epoch: 0030 cost = 1.993916035\n",
      "Epoch: 0031 cost = 1.958694696\n",
      "Epoch: 0032 cost = 1.923517108\n",
      "Epoch: 0033 cost = 1.888608575\n",
      "Epoch: 0034 cost = 1.853893161\n",
      "Epoch: 0035 cost = 1.819055200\n",
      "Epoch: 0036 cost = 1.783552289\n",
      "Epoch: 0037 cost = 1.746693611\n",
      "Epoch: 0038 cost = 1.708172083\n",
      "Epoch: 0039 cost = 1.667952061\n",
      "Epoch: 0040 cost = 1.626141429\n",
      "Epoch: 0041 cost = 1.583044171\n",
      "Epoch: 0042 cost = 1.539054990\n",
      "Epoch: 0043 cost = 1.494633436\n",
      "Epoch: 0044 cost = 1.450385213\n",
      "Epoch: 0045 cost = 1.407046914\n",
      "Epoch: 0046 cost = 1.365635514\n",
      "Epoch: 0047 cost = 1.326981664\n",
      "Epoch: 0048 cost = 1.291193724\n",
      "Epoch: 0049 cost = 1.258210063\n",
      "Epoch: 0050 cost = 1.228091359\n",
      "Epoch: 0051 cost = 1.200715184\n",
      "Epoch: 0052 cost = 1.175695896\n",
      "Epoch: 0053 cost = 1.152504444\n",
      "Epoch: 0054 cost = 1.130888462\n",
      "Epoch: 0055 cost = 1.110659957\n",
      "Epoch: 0056 cost = 1.091653347\n",
      "Epoch: 0057 cost = 1.073763728\n",
      "Epoch: 0058 cost = 1.056859493\n",
      "Epoch: 0059 cost = 1.040897846\n",
      "Epoch: 0060 cost = 1.025841236\n",
      "Epoch: 0061 cost = 1.011677265\n",
      "Epoch: 0062 cost = 0.998436391\n",
      "Epoch: 0063 cost = 0.986261427\n",
      "Epoch: 0064 cost = 0.975059927\n",
      "Epoch: 0065 cost = 0.964605570\n",
      "Epoch: 0066 cost = 0.954825997\n",
      "Epoch: 0067 cost = 0.945712566\n",
      "Epoch: 0068 cost = 0.937208235\n",
      "Epoch: 0069 cost = 0.929304957\n",
      "Epoch: 0070 cost = 0.921989083\n",
      "Epoch: 0071 cost = 0.915349007\n",
      "Epoch: 0072 cost = 0.909758389\n",
      "Epoch: 0073 cost = 0.906726360\n",
      "Epoch: 0074 cost = 0.911347210\n",
      "Epoch: 0075 cost = 0.924612701\n",
      "Epoch: 0076 cost = 0.985845864\n",
      "Epoch: 0077 cost = 1.121117711\n",
      "Epoch: 0078 cost = 4.170381546\n",
      "Epoch: 0079 cost = 2.255500555\n",
      "Epoch: 0080 cost = 2.272705555\n",
      "Epoch: 0081 cost = 2.055197477\n",
      "Epoch: 0082 cost = 1.824298143\n",
      "Epoch: 0083 cost = 1.269877434\n",
      "Epoch: 0084 cost = 1.154443979\n",
      "Epoch: 0085 cost = 1.122262359\n",
      "Epoch: 0086 cost = 1.097770214\n",
      "Epoch: 0087 cost = 1.049593568\n",
      "Epoch: 0088 cost = 0.769867539\n",
      "Epoch: 0089 cost = 0.479466200\n",
      "Epoch: 0090 cost = 0.405964583\n",
      "Epoch: 0091 cost = 0.362522215\n",
      "Epoch: 0092 cost = 0.341349423\n",
      "Epoch: 0093 cost = 0.330136687\n",
      "Epoch: 0094 cost = 0.322413683\n",
      "Epoch: 0095 cost = 0.316442490\n",
      "Epoch: 0096 cost = 0.311432809\n",
      "Epoch: 0097 cost = 0.307039827\n",
      "Epoch: 0098 cost = 0.303065211\n",
      "Epoch: 0099 cost = 0.299390137\n",
      "Epoch: 0100 cost = 0.295954257\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# train my model\n",
    "print('Learning stared. It takes sometime.')\n",
    "for epoch in range(100):\n",
    "    avg_cost = 0\n",
    "    #sess.run(y_cnn)\n",
    "    #y_cnn = np.array(tf.one_hot(y_train,6))\n",
    "    #total_batch = int(mnist.train.num_examples / batch_size)   \n",
    "    #for i in range(4064):\n",
    "    #batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    #for i in range(4064):\n",
    "    #feed_dict = {X: np.array(x_cnn).reshape([1, 32]), Y: np.array(y_cnn[i]).reshape([-1,1])}\n",
    "    feed_dict = {X: x_cnn.reshape([-1, input_size]), y: np.array(y_train)}\n",
    "    s,c, _, = sess.run([summary, cost, optimizer],feed_dict=feed_dict)       \n",
    "    avg_cost += c / 4064\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00544227  0.00544227  0.00544227  0.00544227  0.93692803  0.00544227\n",
      "   0.00864936  0.00544227  0.00544227  0.00544227  0.00544227  0.00544227]]\n"
     ]
    }
   ],
   "source": [
    "print (sess.run(prediction, feed_dict = {X:msg}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
